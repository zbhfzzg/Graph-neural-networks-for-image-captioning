# Graph-neural-networks-for-image-captioning
Final Year Prject 
##Version 1

激活Anaconda prompt中的环境，需要先管理员启动
conda activate pytorch_dl
缺乏package的话需要通过Anaconda prompt来安装。别的没有用的。

教程1
https://www.datacamp.com/tutorial/comprehensive-introduction-graph-neural-networks-gnns-tutorial

3.20 
学习project： https://github.com/RoyalSkye/Image-Caption
Tut： https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning

Attention. The use of Attention networks is widespread in deep learning, and with good reason. This is a way for a model to choose only those parts of the encoding that it thinks is relevant to the task at hand. The same mechanism you see employed here can be used in any model where the Encoder's output has multiple points in space or time. In image captioning, you consider some pixels more important than others. In sequence to sequence tasks like machine translation, you consider some words more important than others.


### Data set
Fliker 30K dataset. Because MSCOCO is too large
Images and captions link     https://www.kaggle.com/datasets/adityajn105/flickr30k

Fliker 8K    https://www.kaggle.com/datasets/adityajn105/flickr8k